{'limit_num_sen': 25, 'limit_num_words': 13, 'lr': 1e-05, 'lr_edge': 0.1, 'Seed': 1998, 'weight_decay': 0.0005, 'hidden_dim': 100, 'input_dim': 768, 'output_dim': 128, 'final_dim': 2, 'test_perc': 0.1, 'val_perc': 0.11, 'beta': 0.4, 'epoch': 100, 'batch_size': 8, 'device': device(type='cuda', index=0), 'bert_model': 'bert-base-uncased', 'dataset_name': 'politic', 'dataset_path': './data/politic/politic_news.tsv', 'img_path': './data/politic/imgs', 'model_path': './data/politic/politic_checkpoint.pt', 'news_list': './data/politic/politic_news.npy', 'news_label': './data/politic/politic_label.npy', 'news_id': './data/politic/politic_id.npy', 'nodes_num_data': './data/politic/politic_node.npy'}
********************************************************************************
********************************************************************************
********************************************************************************
Constructing Model...
device: cuda:0
init
********************************************************************************
********************************************************************************
Defining Loss Function...
********************************************************************************
********************************************************************************
Taking Adam as the Ooptimizer...
********************************************************************************
the length of news_list is: 661
the length of news_tit_cont is: 661
convert_text_to_token......
  0%|          | 0/661 [00:00<?, ?it/s]  4%|▍         | 27/661 [00:00<00:02, 261.90it/s]  8%|▊         | 54/661 [00:00<00:02, 206.71it/s] 12%|█▏        | 78/661 [00:00<00:02, 215.66it/s] 15%|█▌        | 101/661 [00:00<00:02, 203.43it/s] 20%|█▉        | 130/661 [00:00<00:02, 228.46it/s] 23%|██▎       | 155/661 [00:00<00:02, 233.96it/s] 27%|██▋       | 181/661 [00:00<00:01, 240.43it/s] 31%|███       | 206/661 [00:00<00:01, 234.13it/s] 35%|███▍      | 230/661 [00:01<00:01, 223.70it/s] 39%|███▉      | 259/661 [00:01<00:01, 238.20it/s] 43%|████▎     | 284/661 [00:01<00:01, 239.31it/s] 47%|████▋     | 309/661 [00:01<00:01, 230.58it/s] 50%|█████     | 333/661 [00:01<00:01, 221.70it/s] 54%|█████▍    | 358/661 [00:01<00:01, 227.89it/s] 58%|█████▊    | 384/661 [00:01<00:01, 234.43it/s] 62%|██████▏   | 408/661 [00:01<00:01, 226.13it/s] 65%|██████▌   | 431/661 [00:01<00:01, 220.86it/s] 69%|██████▉   | 455/661 [00:02<00:00, 225.14it/s] 73%|███████▎  | 481/661 [00:02<00:00, 233.26it/s] 76%|███████▋  | 505/661 [00:02<00:00, 225.38it/s] 80%|███████▉  | 528/661 [00:02<00:00, 225.17it/s] 83%|████████▎ | 551/661 [00:02<00:00, 226.51it/s] 87%|████████▋ | 574/661 [00:02<00:00, 220.07it/s] 90%|█████████ | 597/661 [00:02<00:00, 204.91it/s] 94%|█████████▎| 619/661 [00:02<00:00, 207.56it/s] 97%|█████████▋| 640/661 [00:02<00:00, 206.03it/s]100%|██████████| 661/661 [00:03<00:00, 190.29it/s]100%|██████████| 661/661 [00:03<00:00, 220.28it/s]
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
the length of train_news_list is: 528
the length of val_news_list is: 66
the length of test_news_list is: 67
epoch:1

[Batch 0] Begins.
[debug] -1 counter in train_label: 0
=== [DEBUG: Batch 0] ===
train_label: tensor([1, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')
label min/max: 0 / 1
unique labels: [0, 1]
========================
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.03075318969786167 / 0.14520153403282166
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 1] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.04973835125565529 / 0.1904815286397934
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 2] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.04268778860569 / 0.15068356692790985
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 3] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.04142441973090172 / 0.12784670293331146
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 4] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.03638504445552826 / 0.14370889961719513
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 5] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.05027328059077263 / 0.15510594844818115
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 6] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.1471499800682068 / 0.18406742811203003
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 7] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.052568987011909485 / 0.1648341715335846
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 8] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.0979943573474884 / 0.17002983391284943
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 9] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.04549716040492058 / 0.2103537768125534
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 10] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.1000339463353157 / 0.17929209768772125
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 11] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.056959368288517 / 0.15618838369846344
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 12] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.15981872379779816 / 0.20345009863376617
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 13] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.21735034883022308 / 0.3702460527420044
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 14] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.04343588650226593 / 0.1839083433151245
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 15] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.15374721586704254 / 0.19195258617401123
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 16] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -2.67911958694458 / 0.33742406964302063
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 17] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.1108645498752594 / 0.33105501532554626
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 18] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.04425102472305298 / 0.2637540102005005
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 19] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.23222018778324127 / 0.43510520458221436
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 20] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.11148884892463684 / 0.4715019464492798
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 21] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.2879117727279663 / 0.24509011209011078
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 22] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.07051078975200653 / 0.4063180387020111
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 23] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.08261867612600327 / 0.3177970051765442
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 24] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.09367327392101288 / 0.4621436297893524
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 25] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.027558516710996628 / 0.2821168303489685
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 26] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.04112478345632553 / 0.4746584892272949
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 27] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.043475858867168427 / 0.19748258590698242
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 28] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.022249937057495117 / 0.33522939682006836
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 29] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.04060719907283783 / 0.5355101823806763
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 30] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.16417039930820465 / 0.3482457399368286
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 31] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.10536294430494308 / 0.7391571402549744
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 32] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.3231813609600067 / 0.4928511679172516
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 33] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.21627727150917053 / 0.5892018675804138
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 34] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.04407057911157608 / 0.2893635034561157
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 35] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.10464658588171005 / 0.4824248254299164
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 36] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.00993076991289854 / 0.39422407746315
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 37] Begins.
[debug] -1 counter in train_label: 0
[SKIP] Invalid labels at batch 37:
Invalid labels: tensor([-9223372036854775808], device='cuda:0')

[Batch 38] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.08158346265554428 / 0.38790908455848694
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 39] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.036805253475904465 / 0.2952086627483368
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 40] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.18053151667118073 / 0.2681773006916046
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 41] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.02661600522696972 / 0.2569725811481476
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 42] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.17922906577587128 / 0.3708665668964386
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 43] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.09956647455692291 / 0.20561173558235168
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 44] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.12959270179271698 / 0.30742964148521423
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 45] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.2015915960073471 / 0.3023010492324829
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 46] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.04258864372968674 / 0.3018849194049835
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 47] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.056290388107299805 / 0.4605347514152527
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 48] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.4176945388317108 / 0.20048168301582336
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 49] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.06019500643014908 / 0.3980332314968109
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 50] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: 0.0011176824336871505 / 0.5185400247573853
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 51] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.03790247067809105 / 0.35283392667770386
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 52] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.20963254570960999 / 0.1587442308664322
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 53] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.05991451069712639 / 0.2521210014820099
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 54] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.44354182481765747 / 0.271246075630188
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 55] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.18335387110710144 / 0.21530704200267792
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 56] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.09886957705020905 / 0.23629829287528992
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 57] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.17453068494796753 / 0.21144439280033112
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 58] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.15786610543727875 / 0.266203373670578
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 59] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.09410876780748367 / 0.16168160736560822
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 60] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.1106555238366127 / 0.2867638170719147
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 61] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.01975431852042675 / 0.3668960630893707
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 62] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.05847043916583061 / 0.339688241481781
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 63] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.04479961842298508 / 0.2237747609615326
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 64] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.25017645955085754 / 0.4530669152736664
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False

[Batch 65] Begins.
[debug] -1 counter in train_label: 0
[debug] pred_res.shape: torch.Size([8, 2])
[debug] train_label.shape: torch.Size([8])
[debug] label dtype: torch.int64 | pred_res dtype: torch.float32
[debug] device: label(cuda:0) | pred_res(cuda:0)
[debug] label min/max: 0 / 1
[debug] pred_res min/max: -0.07784588634967804 / 0.22101430594921112
[debug] label unique: [0, 1]
[check] any label out of bound? False
[check] any label < 0? False
[check] label requires grad? False
[check] pred_res has NaN? False
[check] pred_res has Inf? False
epoch:1, train_loss: 22.2299......
********epoch:1, val_loss:0.6644,  Acc:0.803, Pre:0.847, Rec:0.803, F1:0.771
Traceback (most recent call last):
  File "/home/charmoyster/Taehun/BREAK-main/main_1.py", line 292, in <module>
    early_stopping(epoch_loss_val, LSSDN)
  File "/home/charmoyster/Taehun/BREAK-main/earlystopping.py", line 37, in __call__
    self.save_checkpoint(val_loss, model)
  File "/home/charmoyster/Taehun/BREAK-main/earlystopping.py", line 54, in save_checkpoint
    torch.save(model.state_dict(), cfg.model_path)     # save the optimal model
  File "/home/charmoyster/miniconda3/envs/Taehun_3.10/lib/python3.10/site-packages/torch/serialization.py", line 849, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/charmoyster/miniconda3/envs/Taehun_3.10/lib/python3.10/site-packages/torch/serialization.py", line 716, in _open_zipfile_writer
    return container(name_or_buffer)
  File "/home/charmoyster/miniconda3/envs/Taehun_3.10/lib/python3.10/site-packages/torch/serialization.py", line 687, in __init__
    super().__init__(torch._C.PyTorchFileWriter(self.name))
RuntimeError: Parent directory model/politic does not exist.
